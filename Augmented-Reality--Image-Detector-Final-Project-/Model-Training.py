# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bXqy7VCNPMdq9-3IYIzuQ482pJyctwxG
"""

#Importing the necessasry libraries -- Training a CNN from scrach on the pre-processed QickDraw dataset from Github
import os
import urllib.request
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Extended class list - common objects useful for VR drawing
# Only verified available classes from Google QuickDraw dataset
CLASS_NAMES = [
    # Animals (7)
    "cat", "dog", "bird", "fish", "bear", "butterfly", "spider",
    # Buildings & Structures (6)
    "house", "castle", "barn", "bridge", "lighthouse", "church",
    # Transportation (5)
    "car", "airplane", "bicycle", "truck", "train",
    # Nature (6)
    "tree", "flower", "sun", "moon", "cloud", "mountain",
    # Common Objects (7)
    "apple", "banana", "book", "chair", "table", "cup", "umbrella",
    # People & Body (4)
    "face", "eye", "hand", "foot",
    # Shapes (4)
    "circle", "triangle", "square", "star",
    # Tools & Items (5)
    "sword", "axe", "hammer", "key", "crown",
    # Musical Instruments (2)
    "guitar", "piano"
]

NUM_CLASSES = len(CLASS_NAMES)
print(f"Training with {NUM_CLASSES} classes")

# Samples per class - adjust based on training time/accuracy needs
# 2000-5000 is good for quick experiments, 10000+ for better accuracy
MAX_ITEMS_PER_CLASS = 5000

# Where to cache the downloaded .npy files and saved model
DATA_DIR = "quickdraw_npy"
MODEL_DIR = "saved_models"
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

print("TensorFlow version:", tf.__version__)
print("Classes:", CLASS_NAMES)

#Download helper -- uses pre processed numpy_bitmap dataset
def download_quickdraw_class(class_name: str) -> np.ndarray:
    """
    Download the preprocessed numpy bitmap (.npy) for one QuickDraw class
    from Google's public bucket, if not already cached.

    Each file contains an array of shape (N, 784) where 784 = 28*28.
    """
    # From the QuickDraw docs:
    # https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/<class>.npy
    url_class_name = class_name.replace(" ", "%20")
    url = f"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{url_class_name}.npy"
    local_path = os.path.join(DATA_DIR, f"{class_name}.npy")

    if not os.path.exists(local_path):
        print(f"\nDownloading {class_name} data from:\n  {url}")
        urllib.request.urlretrieve(url, local_path)
        print("Download complete:", local_path)
    else:
        print(f"\nUsing cached file for {class_name}: {local_path}")

    data = np.load(local_path)
    print(f"{class_name}: {data.shape[0]} total samples available")
    return data

#Loading the data for all classes
all_images = []
all_labels = []

for label_idx, cls in enumerate(CLASS_NAMES):
    data = download_quickdraw_class(cls)

    # Optionally subsample for speed
    if MAX_ITEMS_PER_CLASS is not None:
        data = data[:MAX_ITEMS_PER_CLASS]

    # data shape: (N, 784)
    all_images.append(data)
    all_labels.append(np.full(data.shape[0], label_idx, dtype=np.int64))

# Stack into big arrays
X = np.concatenate(all_images, axis=0)   # (N_total, 784)
y = np.concatenate(all_labels, axis=0)   # (N_total,)

print("\nTotal samples:", X.shape[0])

#Preprocess: reshape & normalize
# (N, 784) -> (N, 28, 28, 1)
X = X.reshape((-1, 28, 28, 1)).astype("float32")

# Normalize pixel values from [0, 255] to [0, 1]
X = X / 255.0

# Train / validation split
X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("Train shape:", X_train.shape, y_train.shape)
print("Val shape:  ", X_val.shape, y_val.shape)

#Visualize a few samples
def show_examples(X_batch, y_batch, class_names, n=9):
    plt.figure(figsize=(4, 4))
    idxs = np.random.choice(len(X_batch), n, replace=False)
    for i, idx in enumerate(idxs):
        plt.subplot(3, 3, i + 1)
        plt.imshow(X_batch[idx].squeeze(), cmap="gray")
        plt.title(class_names[y_batch[idx]])
        plt.axis("off")
    plt.tight_layout()
    plt.show()
show_examples(X_train, y_train, CLASS_NAMES)

#Building a CNN model from scratch
def build_quickdraw_cnn(num_classes: int) -> tf.keras.Model:
    """
    Simple CNN built from scratch for QuickDraw 28x28 grayscale sketches.
    """
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(128, (3, 3), activation="relu"),

        layers.Flatten(),
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.3),
        layers.Dense(num_classes, activation="softmax")
    ])
    return model


model = build_quickdraw_cnn(NUM_CLASSES)
model.summary()

# Compiling the model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# Training the model
print("\n=== Training the Model ===")

# Callbacks for better training
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
    os.path.join(MODEL_DIR, "best_model.keras"),
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

# Train the model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=128,
    callbacks=[early_stopping, model_checkpoint],
    verbose=1
)

# Plot training history
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Model Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Model Loss')

plt.tight_layout()
plt.show()

# Evaluate on validation set
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"\nValidation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

# Save the trained model
keras_path = os.path.join(MODEL_DIR, "quickdraw_house_cat_dog_car.keras")
h5_path    = os.path.join(MODEL_DIR, "quickdraw_house_cat_dog_car.h5")

model.save(keras_path)
model.save(h5_path)

print("\nModel saved to:")
print("  Keras format:", keras_path)
print("  H5 format:   ", h5_path)

#Quick test prediction (optional)

sample_idx = np.random.randint(0, len(X_val))
sample_img = X_val[sample_idx:sample_idx + 1]
pred_probs = model.predict(sample_img, verbose=0)
pred_idx = int(np.argmax(pred_probs))

plt.imshow(sample_img[0].squeeze(), cmap="gray")
plt.title(f"Pred: {CLASS_NAMES[pred_idx]} | True: {CLASS_NAMES[y_val[sample_idx]]}")
plt.axis("off")
plt.show()

import tf2onnx
import onnx
import onnxruntime

import tensorflow as tf
import tf2onnx
import os

# 1. Load model
model = tf.keras.models.load_model("saved_models/quickdraw_house_cat_dog_car.keras")

# 2. Monkey-patch missing attribute for tf2onnx (Keras 3 issue)
model.output_names = [t.name.split(":")[0] for t in model.outputs]

# 3. ONNX export -- Exporting the model for VR use
onnx_path = "saved_models/quickdraw_house_cat_dog_car.onnx"

spec = (tf.TensorSpec((None, 28, 28, 1), tf.float32, name="input"),)

model_proto, _ = tf2onnx.convert.from_keras(
    model,
    input_signature=spec,
    opset=13,
    output_path=onnx_path,
)

print("ONNX model saved to:", onnx_path)